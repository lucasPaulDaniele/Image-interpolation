{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image interpolation - train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gU8V3H3ECUrr"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from cv2 import imread, IMREAD_GRAYSCALE, resize\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTMCell, Dropout, Conv2D, ConvLSTM2D, Conv2DTranspose, MaxPooling2D, concatenate, Bidirectional, LSTM, Reshape, Layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j661AVpGEG5f"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'img' : {\n",
    "        'height' : 128,\n",
    "        'width' : 128,\n",
    "        'n_channels' : 1\n",
    "    },\n",
    "    'batch_size' : 32,\n",
    "    'frame_dist' : 1,\n",
    "    'videos_dir' : \"./youtube\",\n",
    "    'n_past': 1, \n",
    "    'n_future': 1,\n",
    "    'n_channels': 1,\n",
    "    'duration_video' : 5,\n",
    "    'from_fps' : 30\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xZAQx4rFD5LN"
   },
   "source": [
    "## Set custom metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Tf-LwYKJD4Yf"
   },
   "outputs": [],
   "source": [
    "def SAD(y_true, y_pred):\n",
    "    return K.sum(K.abs(y_true - y_pred))//params['batch_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mcLiGKfKE3RT"
   },
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "x0UDb3QizYqE"
   },
   "outputs": [],
   "source": [
    "class Reduction(Layer):\n",
    "  def __init__(self, name='Reduction', pooling=True, filter=16): \n",
    "    self.layers = [\n",
    "        Conv2D(filter, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'),\n",
    "        Dropout(0.1),\n",
    "        Conv2D(filter, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')\n",
    "        ]\n",
    "    if pooling:\n",
    "      self.layers.insert(0, MaxPooling2D((2, 2)))\n",
    "    super().__init__(name=name)\n",
    "   \n",
    "  def call(self, net):\n",
    "    for layer in self.layers:\n",
    "      net = layer(net)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HIvQTWtAzcAx"
   },
   "outputs": [],
   "source": [
    "class Expandation(Layer):\n",
    "  def __init__(self, name='Expandation', filter=16):\n",
    "    self.conv2D_trans = Conv2DTranspose(filter, (2,2), strides=(2,2), padding='same')\n",
    "    self.conv2D_1 = Conv2D(filter, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')\n",
    "    self.conv2D_2 = Conv2D(filter, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')\n",
    "    self.dropout = Dropout(0.1)\n",
    "    super().__init__(name=name)\n",
    "  \n",
    "  def call(self, net, reduction_layer):\n",
    "    net = self.conv2D_trans(net)\n",
    "    net = concatenate([net, reduction_layer])\n",
    "    net = self.conv2D_1(net)\n",
    "    net = self.dropout(net)\n",
    "    net = self.conv2D_2(net)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R0ncEDdNrUj5"
   },
   "outputs": [],
   "source": [
    "class U_net(Layer):\n",
    "  def __init__(self, name='Unet', n_levels=3, starting_number_filters=16, output_dim=(128, 128, 1)):\n",
    "    self.output_dim = output_dim\n",
    "    self.n_levels = n_levels\n",
    "    self.starting_number_filters = starting_number_filters\n",
    "    super().__init__(name=name)\n",
    "\n",
    "    self.conv2D_16 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')\n",
    "    self.conv2D_1 = Conv2D(1, (1, 1), activation='relu', kernel_initializer='he_normal', padding='same')\n",
    "\n",
    "    self.reductions = [Reduction(name='ReductionMASDAC', filter=16, pooling=False)]\n",
    "    for i in range(1, self.n_levels):\n",
    "      filter = starting_number_filters*2**i\n",
    "      self.reductions.append(Reduction(name=f'Reduction{filter}', filter=filter))\n",
    "\n",
    "    self.expandations = []\n",
    "    for i in range(self.n_levels-1):\n",
    "      filter = starting_number_filters*2**(self.n_levels-i-1)\n",
    "      self.expandations.append(Expandation(name=f'Expandation{filter}', filter=filter))\n",
    "  \n",
    "  def get_config(self):\n",
    "      config = super().get_config()\n",
    "      config.update({\n",
    "          \"output_dim\": self.output_dim,\n",
    "          \"n_levels\": self.n_levels,\n",
    "          \"starting_number_filters\": self.starting_number_filters,\n",
    "      })\n",
    "      return config\n",
    "\n",
    "  def build(self, input_shape): \n",
    "    print(input_shape)\n",
    "    self.kernel = self.add_weight(name = 'kernel', shape = (input_shape[1], *self.output_dim), initializer = 'normal', trainable = True) \n",
    "    super().build(input_shape)\n",
    "   \n",
    "  def call(self, input):\n",
    "    reductions = []\n",
    "    for i, reduction in enumerate(self.reductions):\n",
    "      input_layer = reductions[i-1] if i>0 else input\n",
    "      reduction_layer = reduction(input_layer)\n",
    "      reductions.append(reduction_layer)\n",
    "\n",
    "    expandations = []\n",
    "    for i, expandation in enumerate(self.expandations):\n",
    "      input_layer_to_expand = expandations[i-1] if i>0 else reductions[-1]\n",
    "      input_layer_to_concat = reductions[self.n_levels-i-2]\n",
    "      expandation_layer = expandation(input_layer_to_expand, input_layer_to_concat)\n",
    "      expandations.append(expandation_layer)\n",
    "\n",
    "    output = self.conv2D_16(expandations[-1])\n",
    "    output = self.conv2D_1(output)\n",
    "    \n",
    "    return output\n",
    "  \n",
    "  \n",
    "def get_unet():\n",
    "  inputs = Input((params['img']['height'], params['img']['width'], params['img']['n_channels']*2))\n",
    "  unet = U_net(name='unet',output_dim=(params['img']['height'], params['img']['width'], params['img']['n_channels']))\n",
    "  unet_layer = unet(inputs)\n",
    "  model = Model(inputs=inputs, outputs=unet_layer)\n",
    "  model.compile(optimizer='adam', loss='mae')\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "def get_unet_v2():\n",
    "  inputs1 = Input((params['img']['height'], params['img']['width'], params['img']['n_channels']))\n",
    "  inputs2 = Input((params['img']['height'], params['img']['width'], params['img']['n_channels']))\n",
    "\n",
    "  unet = U_net(name='unet')\n",
    "  unet_layer1 = unet(inputs1)\n",
    "  unet_layer2 = unet(inputs2)\n",
    "  concat_ = concatenate([unet_layer1, unet_layer2])\n",
    "  outputs_conv = Conv2D(params['img']['n_channels'], (1, 1), activation='sigmoid')(concat_)\n",
    "\n",
    "  model = Model(inputs=[inputs1, inputs2], outputs=outputs_conv)\n",
    "  model.compile(optimizer='adam', loss='mae')\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilated convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OhTT_TCogBx",
    "outputId": "d9c64b17-cb07-437e-cd32-31f833c4de7d"
   },
   "outputs": [],
   "source": [
    "def dilated_conv():\n",
    "  inputs = Input((params['img']['height'], params['img']['width'], params['n_past']+params['n_future']))\n",
    "\n",
    "  dc = Conv2D(16, (3, 3), activation='relu', dilation_rate=(2,2), padding='same') (inputs)\n",
    "  dc = Conv2D(32, (3, 3), activation='relu', dilation_rate=(2,2), padding='same') (dc)\n",
    "  dc = Conv2D(64, (3, 3), activation='relu', dilation_rate=(2,2), padding='same') (dc)\n",
    "  dc = Conv2D(128, (3, 3), activation='relu', dilation_rate=(2,2), padding='same') (dc)\n",
    "  outputs_conv = Conv2D(1, (1, 1), activation='linear') (dc)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[outputs_conv])\n",
    "  model.compile(optimizer='adam', loss='mae', metrics=[SAD])\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "def dilated_conv_lstm():\n",
    "  inputs = Input((params['img']['width'], params['img']['height'], params['n_past']+params['n_future']))\n",
    "  reshaped = Reshape((1, params['img']['width'], params['img']['height'], params['n_past']+params['n_future']))(inputs)\n",
    "\n",
    "  dc = ConvLSTM2D(8, (3, 3), activation='relu', dilation_rate=(2,2), padding='same', return_sequences=True) (reshaped)\n",
    "  dc = ConvLSTM2D(16, (3, 3), activation='relu', dilation_rate=(2,2), padding='same', return_sequences=True) (dc)\n",
    "  dc = ConvLSTM2D(32, (3, 3), activation='relu', dilation_rate=(2,2), padding='same', return_sequences=False) (dc)\n",
    "\n",
    "  outputs_conv = Conv2D(1, (1, 1), activation='linear') (dc)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[outputs_conv])\n",
    "  model.compile(optimizer='adam', loss='mae', metrics=[SAD])\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "def dilated_conv_lstm_bidirec():\n",
    "  inputs = Input((params['img']['width'], params['img']['height'], params['n_past']+params['n_future']))\n",
    "  reshaped = Reshape((1, params['img']['width'], params['img']['height'], params['n_past']+params['n_future']))(inputs)\n",
    "\n",
    "  dc = Bidirectional(ConvLSTM2D(8, (3, 3), activation='relu', dilation_rate=(2,2), padding='same', return_sequences=True)) (reshaped)\n",
    "  dc = Bidirectional(ConvLSTM2D(16, (3, 3), activation='relu', dilation_rate=(2,2), padding='same', return_sequences=True)) (dc)\n",
    "  dc = Bidirectional(ConvLSTM2D(32, (3, 3), activation='relu', dilation_rate=(2,2), padding='same', return_sequences=False)) (dc)\n",
    "\n",
    "  outputs_conv = Conv2D(1, (1, 1), activation='linear') (dc)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[outputs_conv])\n",
    "  model.compile(optimizer='adam', loss='mae', metrics=[SAD])\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilated_conv_lstm_bidirec_and_unet():\n",
    "  inputs1 = Input((params['img']['height'], params['img']['width'], params['img']['n_channels']))\n",
    "  inputs2 = Input((params['img']['height'], params['img']['width'], params['img']['n_channels']))\n",
    "  unet = U_net(name='unet')\n",
    "  unet_layer1 = unet(inputs1)\n",
    "  unet_layer2 = unet(inputs2)\n",
    "  outputs_unet = concatenate([unet_layer1, unet_layer2])\n",
    "\n",
    "  inputs = concatenate([inputs1, inputs2])\n",
    "  reshaped = Reshape((1, params['img']['width'], params['img']['height'], params['n_past']+params['n_future']))(inputs)\n",
    "  outputs_conv_lstm = Bidirectional(ConvLSTM2D(8, (3, 3), activation='relu', dilation_rate=(2,2), padding='same', return_sequences=True)) (reshaped)\n",
    "  outputs_conv_lstm = Bidirectional(ConvLSTM2D(16, (3, 3), activation='relu', dilation_rate=(2,2), padding='same', return_sequences=True)) (outputs_conv_lstm)\n",
    "  outputs_conv_lstm = Bidirectional(ConvLSTM2D(32, (3, 3), activation='relu', dilation_rate=(2,2), padding='same', return_sequences=False)) (outputs_conv_lstm)\n",
    "  \n",
    "  concat_ = concatenate([outputs_unet, outputs_conv_lstm])\n",
    "  outputs = Conv2D(params['img']['n_channels'], (1, 1), activation='sigmoid') (concat_)\n",
    "\n",
    "  model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "  model.compile(optimizer='adam', loss='mae', metrics=[SAD])\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "model = dilated_conv_lstm_bidirec_and_unet()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3s_ANxFPFP-t"
   },
   "source": [
    "## Create callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_gI_o1O0FUvD"
   },
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=\"./dilated_conv_lstm_bidirec_and_unet.hdf5\", monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    TensorBoard(logdir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "iE3KieVyRpJ9"
   },
   "source": [
    "## Instanciate data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lP0VAIDoEjeE",
    "outputId": "b40d7846-9c1f-4b69-dee3-8ffa2f22de10"
   },
   "outputs": [],
   "source": [
    "from datagenerators import DataGeneratorDoubleInput, DataGeneratorDoubleInputDict, DataGeneratorSingleInput \n",
    "\n",
    "params_data_generator = {\n",
    "    'batch_size' : params['batch_size'],\n",
    "    'im_size' : (params['img']['height'], params['img']['width']),\n",
    "    'frame_dist' : params['frame_dist'],\n",
    "    'n_past' : params['n_past'],\n",
    "    'n_future' : params['n_future'],\n",
    "    'type_' : 'train'\n",
    "}\n",
    "training_generator = DataGeneratorDoubleInput(**params_data_generator)\n",
    "\n",
    "params_data_generator = {\n",
    "    'batch_size' : params['batch_size'],\n",
    "    'im_size' : (params['img']['height'], params['img']['width']),\n",
    "    'frame_dist' : params['frame_dist'],\n",
    "    'n_past' : params['n_past'],\n",
    "    'n_future' : params['n_future'],\n",
    "    'type_' : 'valid'\n",
    "}\n",
    "validation_generator = DataGeneratorDoubleInput(**params_data_generator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SzaL4nNwX4hi"
   },
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JyZPUpt-PfYi",
    "outputId": "c9755fb4-5485-4ae6-cb3e-00f26db9d0cb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "hist = model.fit(\n",
    "    training_generator,\n",
    "    validation_data = validation_generator,\n",
    "    epochs=10, \n",
    "    workers=30, \n",
    "    use_multiprocessing=True,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "Xret4LzQCbz6",
    "outputId": "d7f4ad9a-1e38-40c1-f91c-5ccc59e06501"
   },
   "outputs": [],
   "source": [
    "model = dilated_conv_lstm_bidirec_and_unet()\n",
    "model.load_weights('dilated_conv_lstm_bidirec_and_unet.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGRROMBY3t1z"
   },
   "outputs": [],
   "source": [
    "batchX, batchY = validation_generator.__getitem__(2792)\n",
    "pred = model.predict(batchX)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12,7))\n",
    "axs[0,0].imshow(batchX[0][0, :, :, 0], cmap='gray')\n",
    "axs[0,1].imshow(batchY[0, :, :, 0], cmap='gray')\n",
    "axs[0,2].imshow(batchX[1][0, :, :, 0], cmap='gray')\n",
    "\n",
    "axs[1,0].imshow(batchX[0][0, :, :, 0], cmap='gray')\n",
    "axs[1,1].imshow(pred[0, :, :, 0], cmap='gray')\n",
    "axs[1,2].imshow(batchX[1][0, :, :, 0], cmap='gray')\n",
    "\n",
    "print('MAE - Batch', mean_absolute_error(batchY.reshape(params['batch_size'], 128*128), pred.reshape(params['batch_size'], 128*128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ns-CJkV_blZQ"
   },
   "outputs": [],
   "source": [
    "batchX, batchY = validation_generator.__getitem__(random.randint(0, len(training_generator)))\n",
    "pred = model.predict(batchX)\n",
    "mean = (batchX[0][:, :, :, 0]+batchX[1][:, :, :, 0])/2\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12,7))\n",
    "axs[0].imshow(batchY[0, :, :, 0], cmap='gray')\n",
    "axs[1].imshow(pred[0, :, :, 0], cmap='gray')\n",
    "axs[2].imshow(mean[0, :, :], cmap='gray')\n",
    "\n",
    "print('MAE - Pred', mean_absolute_error(batchY.reshape(params['batch_size'], 128*128), pred.reshape(params['batch_size'], 128*128)))\n",
    "print('MAE - Mean', mean_absolute_error(batchY.reshape(params['batch_size'], 128*128), mean.reshape(params['batch_size'], 128*128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jkz2rF0CMnp"
   },
   "outputs": [],
   "source": [
    "def model_naif_moyenne(X, y):\n",
    "  return np.array([(x[0][:, :, :, 0]+x[1][:, :, :, 0])/2 for x  in X])\n",
    "\n",
    "X, Y = [], []\n",
    "for k in range(len(validation_generator)//5):\n",
    "  batchX, batchY = validation_generator.__getitem__(k)\n",
    "  X.append(batchX)\n",
    "  Y.append(batchY)\n",
    "\n",
    "pred_moyenne = model_naif_moyenne(X, Y).reshape((-1, params['img']['height']*params['img']['width']))\n",
    "mae_model = model.evaluate([\n",
    "    np.array([x[0][:, :, :, 0] for x  in X]).reshape((-1, params['img']['height'], params['img']['width'],1)), \n",
    "    np.array([x[1][:, :, :, 0] for x  in X]).reshape((-1, params['img']['height'], params['img']['width'],1))],\n",
    "\n",
    "    np.array(Y).reshape((-1, params['img']['height'], params['img']['width'],1))\n",
    ")[0]\n",
    "\n",
    "Y = np.array(Y).reshape((-1, params['img']['height']* params['img']['width']))\n",
    "\n",
    "print('MAE - Moyenne images', mean_absolute_error(Y, pred_moyenne))\n",
    "print('MAE - Modele FCN', mae_model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6nV6Uk4gZn-P",
    "rU3S9hBAX9vH",
    "KvizccOWazQd",
    "rpbL__M5ebgm"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "37083a178839ddb6837eca99e3841ef7be6dad5dc50c6d19829e2187d61ddd5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
